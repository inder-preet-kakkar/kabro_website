[
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "Services offered - One on one consultancy - Research help"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my website ! My name is Inder Preet and I’m a data scientist interested in algorithms and models, I specialize in hardware software codesign for deep learning, a cutting-edge technology that brings machine learning and artificial intelligence to devices at the edge of the network. It involves developing intelligent systems that run on devices with limited computing resources, such as smartphones, robots, wearables, and IoT sensors.\nAdditionally, I have worked on a lot of other things, like, time-series analysis, AI for Earth Observation, Privacy Preserving ML and most recently optimization for energy management in buildings. Checkout my portfolio for more information on all these. \n\n\nGet in touch\nIf you’re interested in learning more about these projects, please don’t hesitate to get in touch. I’m always excited to connect with like-minded individuals and organizations who share my passion for bringing intelligent systems to the edge of the network.\nContact: me[at]inderpreet[dot]ie"
  },
  {
    "objectID": "blog/post1.html",
    "href": "blog/post1.html",
    "title": "Hiring and Managing Data Scientists",
    "section": "",
    "text": "This short post describes some learnings from my experience in Data Science and might give some useful tips for hiring and managing data scientists.\n\nAbout a year ago, I was looking for new a data science role. I had been working as a data scientist in a R&D centre of a university for more than three years and it was time for me to venture into the corporate world. And as with the usual job search I interviewed at a bunch of companies, and most of the interviews went well. Though I made some mistakes in a couple, but one of the interviews with a very well known company went horribly, and it discouraged me a lot as these were the early days of job hunting.\nDoubt about the usefulness of the skills I had learnt working at the university engulfed me and it felt I had to reskill a lot to move into the corporate. But as the overwhelming riptides of that hunt have ceded and having had the time to see for myself over the past year in my current role in the corporate, the intricacies of the data science role in corporations, I have realised that the problem was something else and goes much deeper. And it is about how companies see data scientists.\n\nIn the absence of well defined responsibilities, many companies over expect the skills of a data scientist.\n\nIf you are managing a team of data scientists, you would expect them to create models/algorithms with reasonable performance guarantees that can help your business. Or if it is about getting insights from data, some reliable, interpretable information in the form of reports, graphs, etc. But companies have gone a step ahead, sorry my bad, many steps ahead.\nMany companies, if you are a data scientist, expect you to not only create state-of-the-art models/algorithms but also expect an efficient and well tested code to implement it. It doesn’t end here, it also expects you to handle the data pipelines (which by the way is a data engineer’s job), databases and also make sure that you use the latest tools for deployment, like Docker and also configure those CI/CD pipelines. Woah! The list gets even bigger when data science projects are managed with Scrum.\nWell, I am not advocating that a data scientist should write poor code or be completely unaware of model deployment. But at the same time there is a difference between a data scientist, a data engineer and a software engineer. You need to ask yourself:\n\nWould you ask your accountant to be a lawyer just because they know tax laws?\n\nLet me elaborate, coding is one of the main tools used by data scientists, as such they pick a lot of skills that traditional coders pick like writing clean code, testing it, software design, etc. But at the same time you cannot expect your data scientist to be as proficient in these as a coder. The trend most data science teams are following is making the data scientist do all the jobs that otherwise would fit a software engineer.\nIf you want your data science team to tackle the whole pipeline of creating a ‘deployable’ solution, then make sure you equip them with the necessary skill set either by training them or by getting expert software developers and data engineers helping your team. Though I am not personally in favour of the former, i.e., training data scientists to do everything, because there is always a time constraint involved, you always have a fixed time to do everything. And if you offload deployment to your data scientists you end up spending time that would have gone to model development to model deployment, the result being an inferior deployed model.\nThere is another problem with expecting your data scientists to excel at these skills–\n\nIt is just too damn hard for one person to master so many technical skills.\n\nYou already knew it, but somehow we forget this when we are managing people and have a tendency to make the most out of what we spend on our team.To circle back to that horrible interview, I was being asked about software design patterns, testing frameworks, other coding related and not so much about Machine Learning models. I felt being interviewed for a software engineering job and expressed my concerns to the interviewers. What came after is the second problem with the data science role.\nThe industry still seems to be experimenting with the ideal data science candidate. Data Scientist cadre comes from Statistics, Biology, Physics, Mathematics, Computer Science, and some other eccentric degrees. Masters and bachelors courses in data science are new and will take time to gain traction. As such, even when talking about core data science skills the corpus to go through is extremely large and varied. And no one would disagree that once a data scientist starts working on a project, the knowledge of that domain is paramount to the success of that project.\n\nDomain specific data scientists might be the way ahead.\n\nHence, some companies, have rather smartly, started specialising the data science roles. You will see a ‘marketing data scientist’ role advertised in Dublin quite often. Which I feel is a good start, rather than hiring a data scientist with financial services experience to do marketing related projects. And this is the trend I see ahead and some of you might also find it useful when hiring data scientists to look for domain specific data scientists, of course if it suits you. But many of you will be companies which are just starting off their data science journey and there won’t be many data scientists with that domain knowledge. In that case, use your sane judgement and probably do not hire someone way off, like, a data scientist working for a bank on mainly tabular data may not be the best if you want to do computer vision tasks.\nThis simple sense is not very commonly seen. So, let us delve deeper into it. There are literally thousands of research papers out there with models/algorithms, and some of these have been nicely coded into Python libraries like Sklearn, numpy, pytorch, keras, tensorflow, etc. Contrary to what many think, data science is not about using these off the shelf Python libraries and solve the problem, it still involves a lot of research and innovation, a data scientist has to dwell into the problem make amendments to these to suit their needs and that there is the applied research bit which is still very prevalent in data science problems.\nTo give an example, coming back to that interview, we were talking about hypothesis testing, obviously because the interviewer had a PhD in statistics. Honestly, I was a bit rusty about it and he asked how do you compare your machine learning models if you don’t know about a so and so test. There was an awkward pause because that sounded new, even to the other interviewer. But I went ahead and explained about different metrics that can be used like f1-score, etc. But he soon came back to hypothesis testing.\nAnd here is the problem, hypothesis testing is not very useful for machine learning models because it is quite expensive to compute. For most tests you would want to run your models/algorithms hundreds of times to get a test statistic which has a high enough power. Hence, you seldom see hypothesis testing being used in machine learning literature to compare models. During the two interviews which I had with that company, both of them at least an hour long, that was the only question related to models/algorithms that I was asked. As I said earlier the recommended corpus is too large for data science and this situation was just a symptom of that problem.\nAn alternative and in all ways a better way to interview, if you are interviewing an experienced candidate, would be to ask the candidate about their previous projects, delve deeper into how they chose models, what metrics did they use, did they design new algorithms, etc. And that was precisely my job interview at the company I am currently working and many others for which I interviewed.\n\nTo weave these the threads together here are the two key takeaways if you are managing or hiring data scientists —\n\nData science roles are already very generic, let’s not try to make it even more generic by expecting a data scientist to be a software engineer.\nWhen hiring, value domain expertise or at least the ability of the person being hired to pick up the domain knowledge.\n\n\nHope that gives you some perspective and if you have any suggestions or comments feel free to mention them in the comments below."
  },
  {
    "objectID": "portfolio/AI4EO.html",
    "href": "portfolio/AI4EO.html",
    "title": "AI for Earth Observation",
    "section": "",
    "text": "Summary\nDeveloped standards and specifications for European Space Agency and worked on image segmentation for EO data.\n\n\nThe story\nEarth Observation (EO) data, comprising of data coming from satellites or drones presents vast opportunities for industry and AI. As such, we worked on AIREO with European Space Agency to formulate specifications and standards for EO data so that it can be easily used by the AI community.\nWe gathered surveys from the community and then specified standards for EO data including what metadata should be present and how we can make it easier to ingest EO data into tools commonly used by AI practitioners. Best practices on how to train ML algorithms on EO data were also laid down.\n\n\n\n\n\nFig. 1: Different facets of EO data covered by AIREO specifications\n\n\n\n\nWe also worked on the problem of image segmentation in satellite images. Figure below shows a satellite image on the left with segmentation map consisting of roads, water, buildings and forest.\n\n\n\n\n\nFig. 2: Satellite image on the left with segmentation map showing roads, water, buildings and forest on the right.\n\n\n\n\nA common problem with segmentation in satellite images is that often the ground truth is not completely labelled, e.g., some roads might be left out of the labels in training data. Training a deep neural network becomes difficult as we do not have the complete ground truth, as such we need to design the loss function such that if we are confident enough in some prediction we incorporate that in ground truth. To do that we use GANs (Generative Adversarial Networks) and borrow ideas from two different studies, UNet and one by Mittal et. al. Additional terms to the loss function were added and some modifications to the latter’s pipeline were made. These modifications yielded better segmentation accuracy for some classes in the dataset.\n\n\n\n\n\nFig. 3: Modifications made to GAN: Added additional loss terms, removed a branch. Image source from Mittal et. al. \n\n\n\n\n\n\n\nImportant links\n\nLink to European Space Agency’s AIREO project\nhttps://eo4society.esa.int/projects/aireo/\n\n\nLink to CeADAR’s AI for Earth Observation demonstrator\nhttps://ceadar.ie/blog/ai-for-earth-observation/\n\n\nPublication\n\nAlastair McKinstry, Oisin Boydell, Quan Le, Inder Preet, Jennifer Hanafin, Manuel Fernandez, Adam Warde, Venkatesh Kannan, and Patrick Griffiths, “AI-Ready Training Datasets for Earth Observation: Enabling FAIR data principles for EO training data”. EGU General Assembly, 2021, link."
  },
  {
    "objectID": "portfolio/wind_energy.html",
    "href": "portfolio/wind_energy.html",
    "title": "Wind Energy Analytics",
    "section": "",
    "text": "Summary\nExplored support vector machines for hind casting wind speed data for wind farms and created an open-source library for wind energy analysis.\n\n\nThe story\nWhat started as my master’s thesis on wind resource assessment turned into first open source python library for wind energy analytics. Working at Brightwind Analysis we were looking at ways to predict the wind energy at a site using machine learning. It is necessary to predict it accurately for the next twenty years before setting up a wind farm to evaluate financial viability of setting up a farm. We ended up writing enough code to feel the need to open source it so other analysts can save time using it. It ended up being a popular project with many adopting the tool for their everyday wind energy assessment.\nThe documentation of the library can be found here.\nSome cool things the library can do:\n\n\n\nAdvanced plots for wind analysts\n\n\n\n\n\nFig. 1: Wind rose for turbulence calculation.\n\n\n\n\nAnalyzing different types of wind distribution\n\n\n\n\n\nFig. 3: Wind distribution analysis\n\n\n\n\n\n\n\nShear calculation\n\n\n\n\n\nFig. 2: Shear profile calculation\n\n\n\n\nA suite of wind speed forecasting methods, including ones proposed in my thesis\n\n\n\n\n\nFig. 4: Simple linear regression model for wind speed prediction\n\n\n\n\n\n\n\n\n\nLink to brightwind open-source python library\nhttps://github.com/brightwind-dev/brightwind"
  },
  {
    "objectID": "portfolio/ppml.html",
    "href": "portfolio/ppml.html",
    "title": "Privacy Preserving ML",
    "section": "",
    "text": "Summary\nPedagogic activities for companies wanting to adopt Privacy Preserving Machine Learning (PPML).\n\n\nThe story\nPrivacy is increasingly becoming a concern with vast amounts of data and advanced ML/AI algorithms. There are several ways in which ML can help preserve privacy. In this project at CeADAR, we created a series of short videos covering the different ways like anonymization, synthetic data generation and differential privacy which can be used to make data more private. We also created a short course on PPML accessible to CeADAR’s members. Below we list the pedagogic videos we created during the project.\n\nTechnical discussion with a few industry experts working on PPML \n\n\n\n\nOverview of PPML\n\n\n\nSome use cases for PPML \nSynthetic Data Generation for privacy protection \nDifferential Privacy: Part 1 \n\n\n\nDoes anonymization alone ensure privacy? \nUsing Synthetic Data Vault library \nDifferential Privacy: Part 2"
  },
  {
    "objectID": "portfolio/telecom_data.html",
    "href": "portfolio/telecom_data.html",
    "title": "Telecom Data Analytics",
    "section": "",
    "text": "Summary\nWorked on telecom network data to identify anomalies and correlation between different KPIs to track the source of anomaly.\n\n\nThe story\nWorking with Sonalake state-of-the-art time-series analytics methods were used to solve various problems in telecom network management.\n\nThe first one was trend analysis, where the trends in some key KPIs could help plan a telecom network operator figure out where to install additional capacity and how to plan future expansion. We used decomposition methods to better predict trends in various KPIs.\n\n\n\n\n\nFig. 1: Decomposition of time series to better predict trends in KPIs\n\n\n\n\nAnomaly detection is another area where telecom networks need some automation, as there are literally hundreds of KPIs which they monitor and manually looking for anomalies is not feasible. Automated ways to detect anomalies can improve quality of service. We used several methods to detect anomalies automatically in each of their KPIs and flag them in a timely manner.\n\n\n\n\n\nFig. 2: Anomaly detection in a typical telecom KPI\n\n\n\n\nOnce the anomaly is identified, we also need to ascertain what services would it impact or what could have been the source of the anomaly. This is particularly difficult for telecom data as hundreds of KPIs are involved making their tracking manually, intractable. Hence, we used self organizing maps to automatically find relationships between the KPIs that might suggest which ones can be a probable cause of failure or could be impacted by an anomaly.\n\n\n\n\n\n\nFig. 3: Self organizing map for telecom KPIs\n\n\n\n\n\n\nBlog post from Sonalake’s website summarizing this work\nhttps://sonalake.com/latest/applying-analytics-and-data-science-in-telecoms-network-congestion-forecasting/"
  },
  {
    "objectID": "portfolio/edgeAI.html",
    "href": "portfolio/edgeAI.html",
    "title": "Harware software codesign for Deep Learning",
    "section": "",
    "text": "Summary\nDesigning the whole pipeline – edge based neural network architecture, pruning and quantization techniques and automatic embedded code generation.\n\n\nThe story\nThe work in this project was done mainly under a technology demonstrator (or proof of concept) for CeADAR - Ireland’s Center for Applied AI, which can be checked here. The whole pipeline starting from creating a deep neural network with low memory and computational footprint to pruning and quantizing that network for deployment and finally automatically generating embedded code to deploy the network on an embedded device running ARM processor was created. The diagram below shows this whole pipeline.\n\n\n\n\n\nFig. 1: Overview of complete Edge AI pipeline\n\n\n\n\nCollaborating with Dr. Deepu John, the problem we tackled was anomaly detection in heartbeats and proposed a novel architecture inspired from auto-encoders. Adding additional neurons for feature augmentation to auto-encoders and chopping off the decoded layer we got a classifier with very low memory and computational footprint, making it easier to deploy on edge. The diagram below shows the architecture.\n\n\n\n\n\nFig. 2: Architecture of deep neural network deployed at the edge\n\n\n\n\nWe also created a novel pruning technique based on the ability of neurons to separate classes. This technique was patented and published and the diagram below shows the metric we proposed class-separation score (css). For more details check the paper here.\n\n\n\n\n\nFig. 3: Class-separation-score, a metric we designed to prune neural networks\n\n\n\n\nAlso, a collaboration with UCD Laboratory for Advanced Manufacturing Simulation and Robotics led to the paper, “Review and application of Edge AI solutions for mobile collaborative robotic platforms”, in Procedia CIRP, which can be found here.\nThis is still an exciting field with lots of new inventions coming frequently, like more specialized hardware and Neural Architecture Search (NAS) for the edge.\n\n\n\nImportant links\n\nPublications\n\nI. Preet, O. Boydell and D. John, “Class-Separation Preserving Pruning for Deep Neural Networks,” in IEEE Transactions on Artificial Intelligence, doi: 10.1109/TAI.2022.3228511, link.\nAswin K Ramasubramanian, Robins Mathew, Inder Preet, Nikolaos Papakostas, “Review and application of Edge AI solutions for mobile collaborative robotic platforms”, Procedia CIRP, Volume 107, 2022, link.\n\n\n\nPatent\n‘Class Separation Aware Artificial Neural Network Pruning Method’\nInternational (PCT) Application No. PCT/EP2022/085998\n\n\nVideos\n\nCeADAR Demonstrator: Edge AI\nHardware for Machine Learning, an overview\nPruning and Quantization for DNNs - PyCon Ireland\n\n\n\nLink to CeADAR’s Edge AI demonstrator\nhttps://ceadar.ie/blog/edge-ai/"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Harware software codesign for Deep Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI for Earth Observation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy Preserving ML\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTelecom Data Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWind Energy Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Blog posts here are a mix of technical and non-technical topics, mostly things that I think about. They do not have a set pattern and not all of them would be very thorough. But enjoy anyway ;) !\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nWords\n\n\n\n\n\n\nAug 1, 2023\n\n\nHiring and Managing Data Scientists\n\n\n~1500\n\n\n\n\n\n\nNo matching items"
  }
]