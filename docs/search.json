[
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "Services offered - One on one consultancy - Research help"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my website, KabroAI! My name is Inder Preet and I’m a data scientist interested in algorithms and models specializing in Edge AI, a cutting-edge technology that brings machine learning and artificial intelligence to devices at the edge of the network. It involves developing intelligent systems that run on devices with limited computing resources, such as smartphones, robots, wearables, and IoT sensors.\nIn addition to my work in Edge AI, I have worked on a lot of other things, like, time-series analysis, AI for Earth Observation, Privacy Preserving ML and most recently optimization for energy management in buildings. Checkout my portfolio for more information on all these. \n\n\nGet in touch\nIf you’re interested in learning more about Edge AI or collaborating on a project, please don’t hesitate to get in touch. I’m always excited to connect with like-minded individuals and organizations who share my passion for bringing intelligent systems to the edge of the network.\nContact: singhinderpreet1995[at]gmail[dot]com"
  },
  {
    "objectID": "portfolio/AI4EO.html",
    "href": "portfolio/AI4EO.html",
    "title": "AI for Earth Observation",
    "section": "",
    "text": "Summary\nDeveloped standards and specifications for European Space Agency and worked on image segmentation for EO data.\n\n\nThe story\nEarth Observation (EO) data, comprising of data coming from satellites or drones presents vast opportunities for industry and AI. As such, we worked on AIREO with European Space Agency to formulate specifications and standards for EO data so that it can be easily used by the AI community.\nWe gathered surveys from the community and then specified standards for EO data including what metadata should be present and how can we make it easier to ingest EO data into tools commonly used by AI practitioners. Best practices on how to train ML algorithms on EO data were also laid down.\n\n\n\n\n\nFig. 1: Different facets of EO data covered by AIREO specifications\n\n\n\n\nWe also worked on the problem of image segmentation in satellite images. Figure below shows a satellite image on the left with segmentation map consisting of roads, water, buildings and forest.\n\n\n\n\n\nFig. 2: Satellite image on the left with segmentation map showing roads, water, buildings and forest on the right.\n\n\n\n\nA common problem with segmentation in satellite images is that often the ground truth is not completely labelled, e.g., some roads might be left out of the labels in training data. Training a deep neural network becomes difficult as we do not have the complete ground truth, as such we need to design the loss function such that if we are confident enough in some prediction we incorporate that in ground truth. To do that we use GANs (Generative Adversarial Networks) and borrow ideas from two different studies, UNet and one by Mittal et. al. Additional terms to the loss function were added and some modifications to the latter’s pipeline were done. These modifications yielded better segmentation accuracy for some classes in the dataset.\n\n\n\n\n\nFig. 3: Modifications made to GAN: Added additional loss terms, removed a branch. Image source from Mittal et. al. \n\n\n\n\n\n\n\nImportant links\n\nLink to European Space Agency’s AIREO project\nhttps://eo4society.esa.int/projects/aireo/\n\n\nLink to CeADAR’s AI for Earth Observation demonstrator\nhttps://ceadar.ie/blog/ai-for-earth-observation/\n\n\nPublication\n\nAlastair McKinstry, Oisin Boydell, Quan Le, Inder Preet, Jennifer Hanafin, Manuel Fernandez, Adam Warde, Venkatesh Kannan, and Patrick Griffiths, “AI-Ready Training Datasets for Earth Observation: Enabling FAIR data principles for EO training data”. EGU General Assembly, 2021, link."
  },
  {
    "objectID": "portfolio/ppml.html",
    "href": "portfolio/ppml.html",
    "title": "Privacy Preserving ML",
    "section": "",
    "text": "Summary\nPedagogic activities for companies wanting to adopt Privacy Preserving Machine Learning (PPML).\n\n\nThe story\nPrivacy is increasingly becoming a concern with vast amounts of data and advanced ML/AI algorithms. There are several ways in which ML can help preserve privacy. In this project at CeADAR, we created a series of short videos covering the different ways like anonymization, synthetic data generation and differential privacy which can be used to make data more private. We also created a short course on PPML accessible to CeADAR’s members. Below we list the pedagogic videos we created during the project.\n\nTechnical discussion with a few industry experts working on PPML \nOverview of PPML \nSome use cases for PPML \nDoes anonymization alone ensure privacy? \nSynthetic Data Generation for privacy protection \nUsing Synthetic Data Vault library \nDifferential Privacy: Part 1 \nDifferential Privacy: Part 2"
  },
  {
    "objectID": "portfolio/time_series.html",
    "href": "portfolio/time_series.html",
    "title": "Telecom Data Analytics",
    "section": "",
    "text": "Summary\nWorked on telecom network data to identify anomalies and correlation between different KPIs to track the source of anomaly.\n\n\nThe story\nWorking with Sonalake and their customer Vodafone Ireland we used state-of-the-art time-series analytics methods to solve various problems in telecom network management.\n\nThe first one was trend analysis, where the trends in some key KPIs could help plan the telecom network operator like Vodafone figure out where to install additional capacity and how to plan future expansion. We used decomposition methods to better predict trends in various KPIs.\n\n\n\n\n\nFig. 1: Decomposition of time series to better predict trends in KPIs\n\n\n\n\nAnomaly detection is another area where telecom networks need some, as there are literally hundreds of KPIs a company like Vodafone monitors and automated ways to detect anomalies can improve quality of service. We used several methods to detect anomalies automatically in each of their KPIs and flag them in a timely manner.\n\n\n\n\n\nFig. 2: Anomaly detection in a typical telecom KPI\n\n\n\n\nOnce the anomaly is identified, we also need to ascertain what services would it impact or what could have been the source of the anomaly. This is particularly difficult for telecom data as hundreds of KPIs are involved making their tracking manually intractable. Hence, we used self organizing maps to automatically find relationships between the KPIs that might suggest which ones can be a probable cause of failure or could be impacted by an anomaly.\n\n\n\n\n\n\nFig. 3: Self organizing map for telecom KPIs\n\n\n\n\n\n\nBlog post from Sonalake’s website summarizing this work\nhttps://sonalake.com/latest/applying-analytics-and-data-science-in-telecoms-network-congestion-forecasting/"
  },
  {
    "objectID": "portfolio/edgeAI.html",
    "href": "portfolio/edgeAI.html",
    "title": "Edge AI",
    "section": "",
    "text": "Summary\nDesigning the whole edge AI pipeline – edge based neural network architecture, pruning and quantization techniques and automatic embedded code generation.\n\n\nThe story\nThe work in Edge AI was done mainly under a technology demonstrator (or proof of concept) for CeADAR - Ireland’s Center for Applied AI, which you can check here. The whole edge AI pipeline starting from creating a deep neural network with low memory and computational footprint to pruning and quantizing that network for deployment and finally automatically generating embedded code to deploy the network on an embedded device running ARM processor. The diagram below summarises the project.\n\n\n\n\nFig. 1: Overview of complete Edge AI pipeline\n\n\n\nCollaborating with Dr. Deepu John, the problem we tackled was anomaly detection in heartbeats and we proposed a novel architecture inspired from auto-encoders. Adding additional neurons for feature augmentation to auto-encoders and chopping off the decoded layer we got a classifier with very low memory and computational footprint, making it easier to deploy on edge. The diagram below shows the architecture.\n\n\n\n\nFig. 2: Architecture of deep neural network deployed at the edge\n\n\n\nWe also created a novel pruning technique based on the ability of neurons to separate classes. This technique was patented and published and the diagram below shows the metric we proposed class-separation score (css). For more details check the paper here.\n\n\n\n\nFig. 3: Class-separation-score, a metric we designed to prune neural networks\n\n\n\nOn the side, a collaboration with UCD Laboratory for Advanced Manufacturing Simulation and Robotics led to the paper, “Review and application of Edge AI solutions for mobile collaborative robotic platforms”, in Procedia CIRP, which can be found here.\nEdge AI is still an exciting field with lots of new inventions coming frequently, like more specialized hardware and Neural Architecture Search (NAS) for the edge. I am eager to explore these new areas in edge AI.\n\n\n\nImportant links\n\nPublications\n\nI. Preet, O. Boydell and D. John, “Class-Separation Preserving Pruning for Deep Neural Networks,” in IEEE Transactions on Artificial Intelligence, doi: 10.1109/TAI.2022.3228511, link.\nAswin K Ramasubramanian, Robins Mathew, Inder Preet, Nikolaos Papakostas, “Review and application of Edge AI solutions for mobile collaborative robotic platforms”, Procedia CIRP, Volume 107, 2022, link.\n\n\n\nPatent\n‘Class Separation Aware Artificial Neural Network Pruning Method’\nInternational (PCT) Application No. PCT/EP2022/085998\n\n\nVideos\n\nCeADAR Demonstrator: Edge AI\nHardware for Machine Learning, an overview\n\n\n\nLink to CeADAR’s Edge AI demonstrator\nhttps://ceadar.ie/blog/edge-ai/"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Edge AI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI for Earth Observation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy Preserving ML\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTelecom Data Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWind Energy Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Working on it, stay tuned!\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio/wind_energy.html",
    "href": "portfolio/wind_energy.html",
    "title": "Wind Energy Analytics",
    "section": "",
    "text": "Summary\nExplored support vector machines for hind casting wind speed data for wind farms and created an open-source library for wind energy analysis.\n\n\nThe story\nWhat started as my master’s thesis on wind resource assessment turned into first open source python library for wind energy analytics. We were looking at ways to predict the wind energy at a site using machine learning. It is necessary to predict it accurately for the next twenty years before setting up a wind farm to evaluate financial viability of setting up a farm. We ended up writing enough code to feel the need to open source it so other analysts can find it useful. It ended up being a popular project with many adopting the tool for their everyday wind energy assessment.\nThe documentation of the library can be found here.\nSome cool things the library can do:\n\n\n\nAdvanced plots for wind analysts\n\n\n\n\n\nFig. 1: Wind rose for turbulence calculation.\n\n\n\n\nAnalyzing different types of wind distribution\n\n\n\n\n\nFig. 3: Wind distribution analysis\n\n\n\n\n\n\n\nShear calculation\n\n\n\n\n\nFig. 2: Shear profile calculation\n\n\n\n\nA suite of wind speed forecasting methods, including ones proposed in my thesis\n\n\n\n\n\nFig. 4: Simple linear regression model for wind speed prediction\n\n\n\n\n\n\n\n\n\nLink to brightwind open-source python library\nhttps://github.com/brightwind-dev/brightwind"
  },
  {
    "objectID": "portfolio/telecom_data.html",
    "href": "portfolio/telecom_data.html",
    "title": "Telecom Data Analytics",
    "section": "",
    "text": "Summary\nWorked on telecom network data to identify anomalies and correlation between different KPIs to track the source of anomaly.\n\n\nThe story\nWorking with Sonalake and their customer Vodafone Ireland we used state-of-the-art time-series analytics methods to solve various problems in telecom network management.\n\nThe first one was trend analysis, where the trends in some key KPIs could help plan the telecom network operator like Vodafone figure out where to install additional capacity and how to plan future expansion. We used decomposition methods to better predict trends in various KPIs.\n\n\n\n\n\nFig. 1: Decomposition of time series to better predict trends in KPIs\n\n\n\n\nAnomaly detection is another area where telecom networks need some, as there are literally hundreds of KPIs a company like Vodafone monitors and automated ways to detect anomalies can improve quality of service. We used several methods to detect anomalies automatically in each of their KPIs and flag them in a timely manner.\n\n\n\n\n\nFig. 2: Anomaly detection in a typical telecom KPI\n\n\n\n\nOnce the anomaly is identified, we also need to ascertain what services would it impact or what could have been the source of the anomaly. This is particularly difficult for telecom data as hundreds of KPIs are involved making their tracking manually intractable. Hence, we used self organizing maps to automatically find relationships between the KPIs that might suggest which ones can be a probable cause of failure or could be impacted by an anomaly.\n\n\n\n\n\n\nFig. 3: Self organizing map for telecom KPIs\n\n\n\n\n\n\nBlog post from Sonalake’s website summarizing this work\nhttps://sonalake.com/latest/applying-analytics-and-data-science-in-telecoms-network-congestion-forecasting/"
  }
]