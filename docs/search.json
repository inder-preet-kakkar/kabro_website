[
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "Services offered - One on one consultancy - Research help"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my website ! My name is Inder Preet and I‚Äôm a data scientist interested in algorithms and models, I specialize in hardware software codesign for deep learning, a cutting-edge technology that brings machine learning and artificial intelligence to devices at the edge of the network. It involves developing intelligent systems that run on devices with limited computing resources, such as smartphones, robots, wearables, and IoT sensors.\nAdditionally, I have worked on a lot of other things, like, time-series analysis, AI for Earth Observation, Privacy Preserving ML and most recently optimization for energy management in buildings. Checkout my portfolio for more information on all these. \n\n\nGet in touch\nIf you‚Äôre interested in learning more about these projects, please don‚Äôt hesitate to get in touch. I‚Äôm always excited to connect with like-minded individuals and organizations who share my passion for bringing intelligent systems to the edge of the network.\nContact: me[at]inderpreet[dot]ie"
  },
  {
    "objectID": "blog/responsibility_ltd.html",
    "href": "blog/responsibility_ltd.html",
    "title": "Responsibility Ltd.",
    "section": "",
    "text": "Observe what you say for about two or three days, and think if you really mean what you say or is it only a reverberation of things you have read, heard or seen.\n\nAnd even if it is the latter, have you critically thought about it, about all its facets, nuances, repercussions, etc. Could you be held responsible for what you say? Because somehow, the responsibility of saying what is right has drastically diminished. And especially when we say or write things on social media. The ethical onus of being right is no longer felt by most of us.\nBut the problem has graver consequences than you think, the homogeneity of untested ideas, of wants and aspirations. Let me elaborate on each of these.\nHype around generative AI, have we thought well about it? Hype about data science, how many companies are actually finding data science useful. Most of them are investing in the promise of insights from data. But are these insights valuable for all kinds of businesses? A more specific example, how much of machine learning which is being tried out in the medical domain will see the light of day when they have to go through all the regulations that the tools in the medical domain are usually subjected to. Even if they start it, it will take a decade to go through them.\nMany tech CEOs/CTOs/C-suite which are responsible for taking key decisions are not generally experts in AI but they are experts in running the business. As such, and rightly so, many of them rely on AI experts. But most strategies drown in the sea of self-proclaimed AI experts. Difference between hearsay and reliable references is very hard to tell. If you watch interviews of someone from the C-suite, you can clearly spot what terribly incorrect ideas of certain technologies make their way into the decision making process.\nThere is a phrase, ‚Äòshite talker‚Äô, which I have gotten to know recently and honestly, I am beginning to be fond of. Because it encapsulates the pride and confidence one feels, when one is asked to present in a conference, to give a talk, or write something for publishing online or even when asked for advice. Somehow we get so elated when we get these opportunities that we end up blabbering ideas, exuding confidence, in things we haven‚Äôt given much thought about. That is why I think we should always take someone speaking at a podium or a ‚Äòfireside chat‚Äô with a pinch of salt. Very few of us have been able to overcome this demon of herofying ourselves when we get these chances to express ourselves to a broader audience, who in our mind at least, hold us in high regard.\nLet me share an anecdote here.\nI was once attending a talk of a renowned professor in Dublin, he was from Stanford and quite a few big names from Dublin‚Äôs AI community had gathered to hear him. He was presenting his research and discussing the \\(r^2\\) metric for his models. I had read in a blog which had cited a paper (which made it very convincing to me) that \\(r^2\\) is not a good metric for non-linear models, so I asked him that question. And the room went awfully quiet for a second and he replied, astonished by the stupidity of the question asked, that it was just not true. My cover had been blown, and the rookie me had been exposed and I am sure some of you can relate to the humiliation of asking a stupid question in front of your peers. That evening I tugged my tail between my legs and went home.\nAfter reaching home I went through the blog again and also through the paper it cited. The paper referenced yet another paper and that paper cited another one. As such, going through a string of five papers over the week, I finally found the ground truth (pun intended üòâ). That paper listed different formulae for calculating \\(r^2\\) and explained the shortcomings of each of them. But it also offered a solution, a formula that doesn‚Äôt suffer from that problem. Somehow all those who based their work on this paper missed the key point of the paper and some of them would definitely have been peer reviewed.\nThis gives me serious trust issues, even more, some of you might be aware of it too, when Nobel worthy research is being discredited because of allegations against the researchers for concocting experimental results. Given these trust issues whenever I am looking for technical information on the web I usually look only at .edu sites from reputed institutes, but I am not convinced that the strategy would hold for long.\nOn a related note, what truly disappoints me is the news, it seems like every news channel has a set template which they try to fit to every story rather than tackling the nuances of things. These templates are ‚Äì rags to riches story, the rich or powerful not caring about the poor, scientific breakthroughs accompanied by women in science, etc. and you see these popping everywhere, news losing its very meaning, rude debates, personal biases of news readers and hosts, etc.\nSomehow I think that there is a part of us that trusts the information in books, in the news, on the internet, on blogs more than it deserves.\nOn the homogeneity of wants and aspirations‚Ä¶\nWe live in a consumerist world where we have somehow ended up producing much more we can consume. Corporations can pay exuberant salaries to MBAs, marketing and sales departments just to get rid of this surplus. Instead of writing more of these hackneyed facts here are some of my thoughts with no particular structure.\n\nWhen Taylor Swift sang Marry me, Juliet, you‚Äôll never have to be alone. Does she really mean it? How many married couples do actually feel they are never alone.\n\n\nDo you need the latest iphone and carry that heavy phone in your pocket? You buy more shite, which in turn propels more people even further to want those things.\n\n\nHow much of your wants and likings are your own and how much have you been conditioned to want? Difficult, might take you a lifetime to figure out.\n\nI have no clear remedy for the issue of taking limited responsibility that I have described here, but an example of a solution.\nOne of my professors back when I was doing my undergrad, Dr.¬†Bikram Phookun is one person that comes to my mind when I imagine someone who has really thought through and internalized what one is saying. Not only were his lectures a delight but otherwise as well he is quite an interesting person to talk to because, it seems to me, he has thought very deeply even about things we take for granted and has in turn given them a flavor of his own understanding. I always make it a point to read his social media posts no matter how lengthy they are or what they are about. My only regret is that he doesn‚Äôt post very often.\nBut maybe that is the price we pay for taking responsibility, we won‚Äôt have much to say. But what we say would be worth listening and trusting. And, if this article with a lot of scattered thoughts renders you mute and anxious about saying anything at least for a day I would consider a job well done."
  },
  {
    "objectID": "blog/hiring_and_managing_data_scientists.html",
    "href": "blog/hiring_and_managing_data_scientists.html",
    "title": "Hiring and Managing Data Scientists",
    "section": "",
    "text": "This short post describes some learnings from my experience in Data Science and might give some useful tips for hiring and managing data scientists.\n\nAbout a year ago, I was looking for a new data science role. I had been working as a data scientist in an R&D centre of a university for more than three years and it was time for me to venture into the corporate world. And as with the usual job search I interviewed at a bunch of companies, and most of the interviews went well. Though I made some mistakes in a couple, but one of the interviews with a very well known company went horribly, and it discouraged me a lot as these were the early days of job hunting.\nDoubt about the usefulness of the skills I had learnt working at the university engulfed me and it felt I had to reskill a lot to move into the corporate. But as the overwhelming riptides of that hunt have ceded and having had the time to see for myself over the past year in my current role in the corporate, the intricacies of the data science role in corporations, I have realised that the problem was something else and goes much deeper. And it is about how companies see data scientists.\n\nIn the absence of well defined responsibilities, many companies over expect the skills of a data scientist.\n\nIf you are managing a team of data scientists, you would expect them to create models/algorithms with reasonable performance guarantees that can help your business. Or if it is about getting insights from data, some reliable, interpretable information in the form of reports, graphs, etc. But companies have gone a step ahead, sorry my bad, many steps ahead.\nMany companies, if you are a data scientist, expect you to not only create state-of-the-art models/algorithms but also expect an efficient and well tested code to implement it. It doesn‚Äôt end here, it also expects you to handle the data pipelines (which by the way is a data engineer‚Äôs job), databases and also make sure that you use the latest tools for deployment, like Docker and also configure those CI/CD pipelines. Woah! The list gets even bigger when data science projects are managed with Scrum.\nWell, I am not advocating that a data scientist should write poor code or be completely unaware of model deployment. But at the same time there is a difference between a data scientist, a data engineer and a software engineer. You need to ask yourself:\n\nWould you ask your accountant to be a lawyer just because they know tax laws?\n\nLet me elaborate, coding is one of the main tools used by data scientists, as such they pick a lot of skills that traditional coders pick like writing clean code, testing it, software design, etc. But at the same time you cannot expect your data scientist to be as proficient in these as a coder. The trend most data science teams are following is making the data scientist do all the jobs that otherwise would fit a software engineer.\nIf you want your data science team to tackle the whole pipeline of creating a ‚Äòdeployable‚Äô solution, then make sure you equip them with the necessary skill set either by training them or by getting expert software developers and data engineers helping your team. Though I am not personally in favour of the former, i.e., training data scientists to do everything, because there is always a time constraint involved, you always have a fixed time to do everything. And if you offload deployment to your data scientists you end up spending time that would have gone to model development to model deployment, the result being an inferior deployed model.\nThere is another problem with expecting your data scientists to excel at these skills‚Äì\n\nIt is just too damn hard for one person to master so many technical skills.\n\nYou already knew it, but somehow we forget this when we are managing people and have a tendency to make the most out of what we spend on our team. To circle back to that horrible interview, I was being asked about software design patterns, testing frameworks, other coding related and not so much about Machine Learning models. I felt being interviewed for a software engineering job and expressed my concerns to the interviewers. What came after is the second problem with the data science role.\nThe industry still seems to be experimenting with the ideal data science candidate. Data Scientist cadre comes from Statistics, Biology, Physics, Mathematics, Computer Science, and some other eccentric degrees. Masters and bachelors courses in data science are new and will take time to gain traction. As such, even when talking about core data science skills the corpus to go through is extremely large and varied. And no one would disagree that once a data scientist starts working on a project, the knowledge of that domain is paramount to the success of that project.\n\nDomain specific data scientists might be the way ahead.\n\nHence, some companies, have rather smartly, started specialising the data science roles. You will see a ‚Äòmarketing data scientist‚Äô role advertised in Dublin quite often. Which I feel is a good start, rather than hiring a data scientist with financial services experience to do marketing related projects. And this is the trend I see ahead and some of you might also find it useful when hiring data scientists to look for domain specific data scientists, of course if it suits you. But many of you will be companies which are just starting off their data science journey and there won‚Äôt be many data scientists with that domain knowledge. In that case, use your sane judgement and probably do not hire someone way off, like, a data scientist working for a bank on mainly tabular data may not be the best if you want to do computer vision tasks.\nThis simple sense is not very commonly seen. So, let us delve deeper into it. There are literally thousands of research papers out there with models/algorithms, and some of these have been nicely coded into Python libraries like Sklearn, numpy, pytorch, keras, tensorflow, etc. Contrary to what many think, data science is not about using these off the shelf Python libraries and solve the problem, it still involves a lot of research and innovation, a data scientist has to dwell into the problem, make amendments to these to suit their needs and that there is the applied research bit which is still very prevalent in data science problems.\nTo give an example, coming back to that interview, we were talking about hypothesis testing, obviously because the interviewer had a PhD in statistics. Honestly, I was a bit rusty about it and he asked, ‚ÄòHow do you compare your machine learning models if you don‚Äôt know about a so and so test‚Äô. There was an awkward pause because that sounded new, even to the other interviewer. But I went ahead and explained about different metrics that can be used like f1-score, etc. But he soon came back to hypothesis testing.\nAnd here is the problem, hypothesis testing is not very useful for machine learning models because it is quite expensive to compute. For most tests you would want to run your models/algorithms hundreds of times to get a test statistic which has a high enough power. Hence, you seldom see hypothesis testing being used in machine learning literature to compare models. During the two interviews which I had with that company, both of them at least an hour long, that was the only question related to models/algorithms that I was asked. As I said earlier,quarto the recommended corpus is too large for data science and this situation was just a symptom of that problem. An alternative and in all ways a better way to interview, if you are interviewing an experienced candidate, would be to ask the candidate about their previous projects, delve deeper into how they chose models, what metrics did they use, did they design new algorithms, etc. And that was precisely my job interview at the company I am currently working for and many others for which I interviewed.\n\nTo weave these threads together here are the two key takeaways if you are managing or hiring data scientists ‚Äî\n\nData science roles are already very generic, let‚Äôs not try to make it even more generic by expecting a data scientist to be a software engineer.\nWhen hiring, value domain expertise or at least the ability of the person being hired to pick up the domain knowledge.\n\n\nHope that gives you some perspective and if you have any suggestions or comments feel free to mention them below."
  },
  {
    "objectID": "portfolio/AI4EO.html",
    "href": "portfolio/AI4EO.html",
    "title": "AI for Earth Observation",
    "section": "",
    "text": "Summary\nDeveloped standards and specifications for European Space Agency and worked on image segmentation for EO data.\n\n\nThe story\nEarth Observation (EO) data, comprising of data coming from satellites or drones presents vast opportunities for industry and AI. As such, we worked on AIREO with European Space Agency to formulate specifications and standards for EO data so that it can be easily used by the AI community.\nWe gathered surveys from the community and then specified standards for EO data including what metadata should be present and how we can make it easier to ingest EO data into tools commonly used by AI practitioners. Best practices on how to train ML algorithms on EO data were also laid down.\n\n\n\n\n\nFig. 1: Different facets of EO data covered by AIREO specifications\n\n\n\n\nWe also worked on the problem of image segmentation in satellite images. Figure below shows a satellite image on the left with segmentation map consisting of roads, water, buildings and forest.\n\n\n\n\n\nFig. 2: Satellite image on the left with segmentation map showing roads, water, buildings and forest on the right.\n\n\n\n\nA common problem with segmentation in satellite images is that often the ground truth is not completely labelled, e.g., some roads might be left out of the labels in training data. Training a deep neural network becomes difficult as we do not have the complete ground truth, as such we need to design the loss function such that if we are confident enough in some prediction we incorporate that in ground truth. To do that we use GANs (Generative Adversarial Networks) and borrow ideas from two different studies, UNet and one by Mittal et. al. Additional terms to the loss function were added and some modifications to the latter‚Äôs pipeline were made. These modifications yielded better segmentation accuracy for some classes in the dataset.\n\n\n\n\n\nFig. 3: Modifications made to GAN: Added additional loss terms, removed a branch. Image source from Mittal et. al.¬†\n\n\n\n\n\n\n\nImportant links\n\nLink to European Space Agency‚Äôs AIREO project\nhttps://eo4society.esa.int/projects/aireo/\n\n\nLink to CeADAR‚Äôs AI for Earth Observation demonstrator\nhttps://ceadar.ie/blog/ai-for-earth-observation/\n\n\nPublication\n\nAlastair McKinstry, Oisin Boydell, Quan Le, Inder Preet, Jennifer Hanafin, Manuel Fernandez, Adam Warde, Venkatesh Kannan, and Patrick Griffiths, ‚ÄúAI-Ready Training Datasets for Earth Observation: Enabling FAIR data principles for EO training data‚Äù. EGU General Assembly, 2021, link."
  },
  {
    "objectID": "portfolio/wind_energy.html",
    "href": "portfolio/wind_energy.html",
    "title": "Wind Energy Analytics",
    "section": "",
    "text": "Summary\nExplored support vector machines for hind casting wind speed data for wind farms and created an open-source library for wind energy analysis.\n\n\nThe story\nWhat started as my master‚Äôs thesis on wind resource assessment turned into first open source python library for wind energy analytics. Working at Brightwind Analysis we were looking at ways to predict the wind energy at a site using machine learning. It is necessary to predict it accurately for the next twenty years before setting up a wind farm to evaluate financial viability of setting up a farm. We ended up writing enough code to feel the need to open source it so other analysts can save time using it. It ended up being a popular project with many adopting the tool for their everyday wind energy assessment.\nThe documentation of the library can be found here.\nSome cool things the library can do:\n\n\n\nAdvanced plots for wind analysts\n\n\n\n\n\nFig. 1: Wind rose for turbulence calculation.\n\n\n\n\nAnalyzing different types of wind distribution\n\n\n\n\n\nFig. 3: Wind distribution analysis\n\n\n\n\n\n\n\nShear calculation\n\n\n\n\n\nFig. 2: Shear profile calculation\n\n\n\n\nA suite of wind speed forecasting methods, including ones proposed in my thesis\n\n\n\n\n\nFig. 4: Simple linear regression model for wind speed prediction\n\n\n\n\n\n\n\n\n\nLink to brightwind open-source python library\nhttps://github.com/brightwind-dev/brightwind"
  },
  {
    "objectID": "portfolio/ppml.html",
    "href": "portfolio/ppml.html",
    "title": "Privacy Preserving ML",
    "section": "",
    "text": "Summary\nPedagogic activities for companies wanting to adopt Privacy Preserving Machine Learning (PPML).\n\n\nThe story\nPrivacy is increasingly becoming a concern with vast amounts of data and advanced ML/AI algorithms. There are several ways in which ML can help preserve privacy. In this project at CeADAR, we created a series of short videos covering the different ways like anonymization, synthetic data generation and differential privacy which can be used to make data more private. We also created a short course on PPML accessible to CeADAR‚Äôs members. Below we list the pedagogic videos we created during the project.\n\nTechnical discussion with a few industry experts working on PPML \n\n\n\n\nOverview of PPML\n\n\n\nSome use cases for PPML \nSynthetic Data Generation for privacy protection \nDifferential Privacy: Part 1 \n\n\n\nDoes anonymization alone ensure privacy? \nUsing Synthetic Data Vault library \nDifferential Privacy: Part 2"
  },
  {
    "objectID": "portfolio/telecom_data.html",
    "href": "portfolio/telecom_data.html",
    "title": "Telecom Data Analytics",
    "section": "",
    "text": "Summary\nWorked on telecom network data to identify anomalies and correlation between different KPIs to track the source of anomaly.\n\n\nThe story\nWorking with Sonalake state-of-the-art time-series analytics methods were used to solve various problems in telecom network management.\n\nThe first one was trend analysis, where the trends in some key KPIs could help plan a telecom network operator figure out where to install additional capacity and how to plan future expansion. We used decomposition methods to better predict trends in various KPIs.\n\n\n\n\n\nFig. 1: Decomposition of time series to better predict trends in KPIs\n\n\n\n\nAnomaly detection is another area where telecom networks need some automation, as there are literally hundreds of KPIs which they monitor and manually looking for anomalies is not feasible. Automated ways to detect anomalies can improve quality of service. We used several methods to detect anomalies automatically in each of their KPIs and flag them in a timely manner.\n\n\n\n\n\nFig. 2: Anomaly detection in a typical telecom KPI\n\n\n\n\nOnce the anomaly is identified, we also need to ascertain what services would it impact or what could have been the source of the anomaly. This is particularly difficult for telecom data as hundreds of KPIs are involved making their tracking manually, intractable. Hence, we used self organizing maps to automatically find relationships between the KPIs that might suggest which ones can be a probable cause of failure or could be impacted by an anomaly.\n\n\n\n\n\n\nFig. 3: Self organizing map for telecom KPIs\n\n\n\n\n\n\nBlog post from Sonalake‚Äôs website summarizing this work\nhttps://sonalake.com/latest/applying-analytics-and-data-science-in-telecoms-network-congestion-forecasting/"
  },
  {
    "objectID": "portfolio/edgeAI.html",
    "href": "portfolio/edgeAI.html",
    "title": "Harware software codesign for Deep Learning",
    "section": "",
    "text": "Summary\nDesigning the whole pipeline ‚Äì edge based neural network architecture, pruning and quantization techniques and automatic embedded code generation.\n\n\nThe story\nThe work in this project was done mainly under a technology demonstrator (or proof of concept) for CeADAR - Ireland‚Äôs Center for Applied AI, which can be checked here. The whole pipeline starting from creating a deep neural network with low memory and computational footprint to pruning and quantizing that network for deployment and finally automatically generating embedded code to deploy the network on an embedded device running ARM processor was created. The diagram below shows this whole pipeline.\n\n\n\n\n\nFig. 1: Overview of complete Edge AI pipeline\n\n\n\n\nCollaborating with Dr.¬†Deepu John, the problem we tackled was anomaly detection in heartbeats and proposed a novel architecture inspired from auto-encoders. Adding additional neurons for feature augmentation to auto-encoders and chopping off the decoded layer we got a classifier with very low memory and computational footprint, making it easier to deploy on edge. The diagram below shows the architecture.\n\n\n\n\n\nFig. 2: Architecture of deep neural network deployed at the edge\n\n\n\n\nWe also created a novel pruning technique based on the ability of neurons to separate classes. This technique was patented and published and the diagram below shows the metric we proposed class-separation score (css). For more details check the paper here.\n\n\n\n\n\nFig. 3: Class-separation-score, a metric we designed to prune neural networks\n\n\n\n\nAlso, a collaboration with UCD Laboratory for Advanced Manufacturing Simulation and Robotics led to the paper, ‚ÄúReview and application of Edge AI solutions for mobile collaborative robotic platforms‚Äù, in Procedia CIRP, which can be found here.\nThis is still an exciting field with lots of new inventions coming frequently, like more specialized hardware and Neural Architecture Search (NAS) for the edge.\n\n\n\nImportant links\n\nPublications\n\nI. Preet, O. Boydell and D. John, ‚ÄúClass-Separation Preserving Pruning for Deep Neural Networks,‚Äù in IEEE Transactions on Artificial Intelligence, doi: 10.1109/TAI.2022.3228511, link.\nAswin K Ramasubramanian, Robins Mathew, Inder Preet, Nikolaos Papakostas, ‚ÄúReview and application of Edge AI solutions for mobile collaborative robotic platforms‚Äù, Procedia CIRP, Volume 107, 2022, link.\n\n\n\nPatent\n‚ÄòClass Separation Aware Artificial Neural Network Pruning Method‚Äô\nInternational (PCT) Application No.¬†PCT/EP2022/085998\n\n\nVideos\n\nCeADAR Demonstrator: Edge AI\nHardware for Machine Learning, an overview\nPruning and Quantization for DNNs - PyCon Ireland\n\n\n\nLink to CeADAR‚Äôs Edge AI demonstrator\nhttps://ceadar.ie/blog/edge-ai/"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Harware software codesign for Deep Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI for Earth Observation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy Preserving ML\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTelecom Data Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWind Energy Analytics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Blog posts here are a mix of technical and non-technical topics, mostly things that I think about. They do not have a set pattern and not all of them would be very thorough. But enjoy anyway ;) !\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nWords\n\n\n\n\n\n\nSep 10, 2023\n\n\nResponsibility Ltd.\n\n\n~1200\n\n\n\n\nJul 31, 2023\n\n\nHiring and Managing Data Scientists\n\n\n~1500\n\n\n\n\n\n\nNo matching items"
  }
]